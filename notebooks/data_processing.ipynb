{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93a4dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lbitsiko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/lbitsiko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lbitsiko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# ensure NLTK data is available\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9873289a",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85af5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ndjson(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an NDJSON file of videos/comments, extract/clean text, \n",
    "    tokenize, remove stopwords, lemmatize, and extract hashtags.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "        - desc              : original description text\n",
    "        - isAd              : ad flag (or \"unknown\")\n",
    "        - hashtags          : list of hashtags found in desc\n",
    "        - text_processed    : punctuation-stripped, lowercased text\n",
    "        - tokens            : list of tokens with stopwords removed\n",
    "        - words_lemmatized  : list of lemmatized tokens\n",
    "        - text_lemmatized   : rejoined lemmatized text\n",
    "    \"\"\"\n",
    "    # load\n",
    "    df = pd.read_json(path, lines=True)\n",
    "\n",
    "    # extract desc + ad flag\n",
    "    df['desc'] = df['data'].apply(lambda x: x.get('desc', ''))\n",
    "    df['isAd'] = df['data'].apply(lambda x: x.get('isAd', 'unknown'))\n",
    "\n",
    "    # extract hashtags\n",
    "    df['hashtags'] = df['desc'].apply(lambda txt: re.findall(r'#\\w+', txt))\n",
    "\n",
    "    # lowercase & strip punctuation\n",
    "    df['text_processed'] = (\n",
    "        df['desc']\n",
    "        .str.lower()\n",
    "        .apply(lambda txt: txt.translate(str.maketrans('', '', string.punctuation)))\n",
    "    )\n",
    "\n",
    "    # tokenize\n",
    "    df['tokens'] = df['text_processed'].str.split()\n",
    "\n",
    "    # build stopword set (English + Dutch)\n",
    "    STOP = set(stopwords.words('english')) | set(stopwords.words('dutch'))\n",
    "\n",
    "    # remove stopwords\n",
    "    df['tokens'] = df['tokens'].apply(lambda toks: [w for w in toks if w not in STOP])\n",
    "\n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['words_lemmatized'] = df['tokens'].apply(lambda toks: [lemmatizer.lemmatize(w) for w in toks])\n",
    "\n",
    "    # join lemmatized tokens back to text\n",
    "    df['text_lemmatized'] = df['words_lemmatized'].apply(\" \".join)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2137f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_browsing = preprocess_ndjson(\"../data/archetypes/diabetes/browsing_videos.ndjson\")\n",
    "df_tuning = preprocess_ndjson(\"../data/archetypes/diabetes/tuning_videos.ndjson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2c10be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nav_index</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp_collected</th>\n",
       "      <th>source_platform</th>\n",
       "      <th>source_platform_url</th>\n",
       "      <th>source_url</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>data</th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>isAd</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words_lemmatized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2:46:NaN</td>\n",
       "      <td>7520333299827411968</td>\n",
       "      <td>2025-07-02 07:44:52.678</td>\n",
       "      <td>tiktok.com</td>\n",
       "      <td>https://www.tiktok.com/</td>\n",
       "      <td>https://www.tiktok.com/api/recommend/item_list...</td>\n",
       "      <td>Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...</td>\n",
       "      <td>{'AIGCDescription': '', 'CategoryType': 120, '...</td>\n",
       "      <td>24</td>\n",
       "      <td>ðŸ˜¡ Ismail el Abassi (DENK): Koranschennis moet ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[#denk, #politiek, #tweedekamer, #vjp, #ismail...</td>\n",
       "      <td>ðŸ˜¡ ismail el abassi denk koranschennis moet nÃº ...</td>\n",
       "      <td>[ðŸ˜¡, ismail, el, abassi, denk, koranschennis, n...</td>\n",
       "      <td>[ðŸ˜¡, ismail, el, abassi, denk, koranschennis, n...</td>\n",
       "      <td>ðŸ˜¡ ismail el abassi denk koranschennis nÃº echt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2:46:NaN</td>\n",
       "      <td>7518029148623817728</td>\n",
       "      <td>2025-07-02 07:44:52.680</td>\n",
       "      <td>tiktok.com</td>\n",
       "      <td>https://www.tiktok.com/</td>\n",
       "      <td>https://www.tiktok.com/api/recommend/item_list...</td>\n",
       "      <td>Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...</td>\n",
       "      <td>{'AIGCDescription': '', 'CategoryType': 101, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>#fyp #fypã‚· #movie #film</td>\n",
       "      <td>False</td>\n",
       "      <td>[#fyp, #fypã‚·, #movie, #film]</td>\n",
       "      <td>fyp fypã‚· movie film</td>\n",
       "      <td>[fyp, fypã‚·, movie, film]</td>\n",
       "      <td>[fyp, fypã‚·, movie, film]</td>\n",
       "      <td>fyp fypã‚· movie film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nav_index              item_id     timestamp_collected source_platform  \\\n",
       "0  2:46:NaN  7520333299827411968 2025-07-02 07:44:52.678      tiktok.com   \n",
       "1  2:46:NaN  7518029148623817728 2025-07-02 07:44:52.680      tiktok.com   \n",
       "\n",
       "       source_platform_url                                         source_url  \\\n",
       "0  https://www.tiktok.com/  https://www.tiktok.com/api/recommend/item_list...   \n",
       "1  https://www.tiktok.com/  https://www.tiktok.com/api/recommend/item_list...   \n",
       "\n",
       "                                          user_agent  \\\n",
       "0  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...   \n",
       "1  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...   \n",
       "\n",
       "                                                data  id  \\\n",
       "0  {'AIGCDescription': '', 'CategoryType': 120, '...  24   \n",
       "1  {'AIGCDescription': '', 'CategoryType': 101, '...  25   \n",
       "\n",
       "                                                desc   isAd  \\\n",
       "0  ðŸ˜¡ Ismail el Abassi (DENK): Koranschennis moet ...  False   \n",
       "1                           #fyp #fypã‚· #movie #film   False   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [#denk, #politiek, #tweedekamer, #vjp, #ismail...   \n",
       "1                       [#fyp, #fypã‚·, #movie, #film]   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  ðŸ˜¡ ismail el abassi denk koranschennis moet nÃº ...   \n",
       "1                               fyp fypã‚· movie film    \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [ðŸ˜¡, ismail, el, abassi, denk, koranschennis, n...   \n",
       "1                           [fyp, fypã‚·, movie, film]   \n",
       "\n",
       "                                    words_lemmatized  \\\n",
       "0  [ðŸ˜¡, ismail, el, abassi, denk, koranschennis, n...   \n",
       "1                           [fyp, fypã‚·, movie, film]   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  ðŸ˜¡ ismail el abassi denk koranschennis nÃº echt ...  \n",
       "1                                fyp fypã‚· movie film  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuning.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddeb5825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nav_index</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp_collected</th>\n",
       "      <th>source_platform</th>\n",
       "      <th>source_platform_url</th>\n",
       "      <th>source_url</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>data</th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>isAd</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words_lemmatized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2:69:NaN</td>\n",
       "      <td>7514764087192996864</td>\n",
       "      <td>2025-07-02 10:07:46.550</td>\n",
       "      <td>tiktok.com</td>\n",
       "      <td>https://www.tiktok.com/</td>\n",
       "      <td>https://www.tiktok.com/api/recommend/item_list...</td>\n",
       "      <td>Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...</td>\n",
       "      <td>{'AIGCDescription': '', 'CategoryType': 101, '...</td>\n",
       "      <td>2015</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2:69:NaN</td>\n",
       "      <td>7519346976580733952</td>\n",
       "      <td>2025-07-02 10:07:46.553</td>\n",
       "      <td>tiktok.com</td>\n",
       "      <td>https://www.tiktok.com/</td>\n",
       "      <td>https://www.tiktok.com/api/recommend/item_list...</td>\n",
       "      <td>Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...</td>\n",
       "      <td>{'AIGCDescription': '', 'CategoryType': 120, '...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Spidey makes a tradeâ€¦ will it be an upgrade? #...</td>\n",
       "      <td>False</td>\n",
       "      <td>[#FitSwap, #SpiderMan, #Marvel]</td>\n",
       "      <td>spidey makes a tradeâ€¦ will it be an upgrade fi...</td>\n",
       "      <td>[spidey, makes, tradeâ€¦, upgrade, fitswap, raym...</td>\n",
       "      <td>[spidey, make, tradeâ€¦, upgrade, fitswap, raymo...</td>\n",
       "      <td>spidey make tradeâ€¦ upgrade fitswap raymond wei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nav_index              item_id     timestamp_collected source_platform  \\\n",
       "0  2:69:NaN  7514764087192996864 2025-07-02 10:07:46.550      tiktok.com   \n",
       "1  2:69:NaN  7519346976580733952 2025-07-02 10:07:46.553      tiktok.com   \n",
       "\n",
       "       source_platform_url                                         source_url  \\\n",
       "0  https://www.tiktok.com/  https://www.tiktok.com/api/recommend/item_list...   \n",
       "1  https://www.tiktok.com/  https://www.tiktok.com/api/recommend/item_list...   \n",
       "\n",
       "                                          user_agent  \\\n",
       "0  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...   \n",
       "1  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:139...   \n",
       "\n",
       "                                                data    id  \\\n",
       "0  {'AIGCDescription': '', 'CategoryType': 101, '...  2015   \n",
       "1  {'AIGCDescription': '', 'CategoryType': 120, '...  2016   \n",
       "\n",
       "                                                desc   isAd  \\\n",
       "0                                                     False   \n",
       "1  Spidey makes a tradeâ€¦ will it be an upgrade? #...  False   \n",
       "\n",
       "                          hashtags  \\\n",
       "0                               []   \n",
       "1  [#FitSwap, #SpiderMan, #Marvel]   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0                                                      \n",
       "1  spidey makes a tradeâ€¦ will it be an upgrade fi...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                                                 []   \n",
       "1  [spidey, makes, tradeâ€¦, upgrade, fitswap, raym...   \n",
       "\n",
       "                                    words_lemmatized  \\\n",
       "0                                                 []   \n",
       "1  [spidey, make, tradeâ€¦, upgrade, fitswap, raymo...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0                                                     \n",
       "1  spidey make tradeâ€¦ upgrade fitswap raymond wei...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_browsing.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e683d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_elements(set1, set2, sample_n=10):\n",
    "    \"\"\"Return the intersection and a sample of common elements.\"\"\"\n",
    "    common = set1.intersection(set2)\n",
    "    print(f\"Number of common elements: {len(common)}\")\n",
    "    print(\"Sample common elements:\", list(common)[:sample_n])\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3284bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common elements: 118\n",
      "Sample common elements: ['#netherlands', '#politiek', '#Friends', '#viraltiktok', '#sad', '#relatable', '#fast', '#netflix', '#foruyou', '#videoviral']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'#2025',\n",
       " '#CapCut',\n",
       " '#FYP',\n",
       " '#FallonTonight',\n",
       " '#Friends',\n",
       " '#HarryPotter',\n",
       " '#JimmyFallon',\n",
       " '#Tatcha',\n",
       " '#TonightShow',\n",
       " '#ad',\n",
       " '#ai',\n",
       " '#america',\n",
       " '#animation',\n",
       " '#animations',\n",
       " '#anime',\n",
       " '#baby',\n",
       " '#blowthisup',\n",
       " '#breakingnews',\n",
       " '#business',\n",
       " '#chatgpt',\n",
       " '#comedy',\n",
       " '#contentcreator',\n",
       " '#corecore',\n",
       " '#creatorsearchinsights',\n",
       " '#dance',\n",
       " '#denk',\n",
       " '#edit',\n",
       " '#edits',\n",
       " '#engage',\n",
       " '#europe',\n",
       " '#f',\n",
       " '#family',\n",
       " '#familyguy',\n",
       " '#fast',\n",
       " '#film',\n",
       " '#fnaf',\n",
       " '#fortnite',\n",
       " '#foruyou',\n",
       " '#foryou',\n",
       " '#foryoupage',\n",
       " '#foryourpage',\n",
       " '#foryouu',\n",
       " '#france',\n",
       " '#fruits',\n",
       " '#funny',\n",
       " '#fy',\n",
       " '#fyp',\n",
       " '#fypage',\n",
       " '#fypppppppppppppp',\n",
       " '#fyppppppppppppppppppppppp',\n",
       " '#fypã‚·',\n",
       " '#fyyyyyyyyyyyyyyyy',\n",
       " '#god',\n",
       " '#googleveo',\n",
       " '#goviral',\n",
       " '#healthyrecipes',\n",
       " '#holland',\n",
       " '#humor',\n",
       " '#itadoriyuuji',\n",
       " '#jamaica',\n",
       " '#jamaicatiktok',\n",
       " '#jesuslovesyou',\n",
       " '#jjk',\n",
       " '#jujutsukaisen',\n",
       " '#learnontiktok',\n",
       " '#life',\n",
       " '#love',\n",
       " '#loveislandusa',\n",
       " '#marketing',\n",
       " '#mindset',\n",
       " '#minecraft',\n",
       " '#momtok',\n",
       " '#motivation',\n",
       " '#movie',\n",
       " '#netflix',\n",
       " '#netherlands',\n",
       " '#nostalgia',\n",
       " '#persian',\n",
       " '#podcast',\n",
       " '#politie',\n",
       " '#politiek',\n",
       " '#pourtoi',\n",
       " '#randomvideo',\n",
       " '#real',\n",
       " '#relatable',\n",
       " '#relationship',\n",
       " '#repost',\n",
       " '#reunion',\n",
       " '#roblox',\n",
       " '#rotterdam',\n",
       " '#sad',\n",
       " '#selfimprovement',\n",
       " '#song',\n",
       " '#songs',\n",
       " '#spoiled',\n",
       " '#streamer',\n",
       " '#summer',\n",
       " '#tiktok',\n",
       " '#travel',\n",
       " '#trend',\n",
       " '#trending',\n",
       " '#trendingvideo',\n",
       " '#tweedekamer',\n",
       " '#unitedkingdom',\n",
       " '#unitedstates',\n",
       " '#usa',\n",
       " '#veo3',\n",
       " '#videoviral',\n",
       " '#viral',\n",
       " '#viraltiktok',\n",
       " '#viralvideo',\n",
       " '#viralvideos',\n",
       " '#vjp',\n",
       " '#voiceover',\n",
       " '#wockst',\n",
       " '#xybca',\n",
       " '#xyzbca',\n",
       " '#y'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_common_elements(\n",
    "    set([token for token_list in df_browsing['hashtags'].values for token in token_list]), \n",
    "    set([token for token_list in df_tuning['hashtags'].values for token in token_list])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265aa190",
   "metadata": {},
   "source": [
    "# Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b98e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequencies(df, word_col='words_lemmatized_nltk'):\n",
    "    \"\"\"Return a DataFrame of word frequencies from a column of word lists.\"\"\"\n",
    "    all_words = [word for words_list in df[word_col] for word in words_list]\n",
    "    word_freqs = Counter(all_words)\n",
    "    word_freqs_df = pd.DataFrame.from_dict(word_freqs, orient='index', columns=['count']).reset_index().rename({'index':'word'}, axis=1)\n",
    "    word_freqs_df = word_freqs_df.sort_values(by='count', ascending=False)\n",
    "    return word_freqs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489b43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_browsing_hashtags = get_word_frequencies(df_browsing, 'hashtags')\n",
    "df_tuning_hashtags = get_word_frequencies(df_tuning, 'hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea517192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>#type2diabetes</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>#diabetes</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>#prediabetes</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>#bloodsugar</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#fyp</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>#insulinresistance</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>#t1d</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>#type1diabetes</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>#minecraft</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>#diabetesawareness</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word  count\n",
       "168      #type2diabetes    134\n",
       "43            #diabetes    114\n",
       "170        #prediabetes     93\n",
       "177         #bloodsugar     91\n",
       "9                  #fyp     87\n",
       "172  #insulinresistance     82\n",
       "821                #t1d     53\n",
       "822      #type1diabetes     47\n",
       "453          #minecraft     39\n",
       "174  #diabetesawareness     38"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuning_hashtags.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b1d9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>#fyp</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#foryou</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>#viral</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>#foryoupage</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#fypã‚·</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>#robloxtower</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>#edit</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>#funny</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>#voorjou</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>#trending</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  count\n",
       "28            #fyp    388\n",
       "8          #foryou    102\n",
       "34          #viral     88\n",
       "46     #foryoupage     72\n",
       "4            #fypã‚·     67\n",
       "1277  #robloxtower     57\n",
       "63           #edit     32\n",
       "287         #funny     30\n",
       "66        #voorjou     29\n",
       "40       #trending     28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_browsing_hashtags.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261dce5",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400e4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "def build_hashtag_network_unweighted(df, hashtag_col='hashtags'):\n",
    "    \"\"\"\n",
    "    Build an unweighted co-occurrence network of hashtags from a DataFrame.\n",
    "    Nodes: hashtags\n",
    "    Edges: two hashtags appear together in the same datapoint (row)\n",
    "\n",
    "    Example:\n",
    "\n",
    "    example_df = pd.DataFrame({\n",
    "    'hashtags': [\n",
    "        ['#cat', '#cute', '#pet'],\n",
    "        ['#dog', '#pet'],\n",
    "        ['#cat', '#sleep'],\n",
    "        ['#dog'],\n",
    "        []\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Build the hashtag co-occurrence network\n",
    "    G_example = build_hashtag_network_unweighted(example_df)\n",
    "\n",
    "    Nodes: ['#cat', '#cute', '#pet', '#dog', '#sleep']\n",
    "    Edges: [('#cat', '#cute'), ('#cat', '#pet'), ('#cat', '#sleep'), ('#cute', '#pet'), ('#pet', '#dog')]\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for hashtags in df[hashtag_col]:\n",
    "        if isinstance(hashtags, list) and len(hashtags) > 1:\n",
    "            for h1, h2 in combinations(hashtags, 2):\n",
    "                G.add_edge(h1, h2)\n",
    "        elif isinstance(hashtags, list) and len(hashtags) == 1:\n",
    "            G.add_node(hashtags[0])\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38df4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_overall_network(df_tuning, df_browsing, hashtag_col='hashtags'):\n",
    "    \"\"\"\n",
    "    Build an overall co-occurrence network from both tuning and browsing DataFrames.\n",
    "    \"\"\"\n",
    "    G_tuning = build_hashtag_network_unweighted(df_tuning, hashtag_col)\n",
    "    G_browsing = build_hashtag_network_unweighted(df_browsing, hashtag_col)\n",
    "    \n",
    "    # # Combine the two graphs\n",
    "    # G_overall = nx.compose(G_tuning, G_browsing)\n",
    "\n",
    "    # Combine nodes from both graphs and assign 'origin' attribute\n",
    "    nodes_browsing = set(G_browsing.nodes)\n",
    "    nodes_tuning = set(G_tuning.nodes)\n",
    "\n",
    "    all_nodes = nodes_browsing | nodes_tuning\n",
    "\n",
    "    # Build mapping for node origins\n",
    "    node_origin = {}\n",
    "    for node in all_nodes:\n",
    "        if node in nodes_browsing and node in nodes_tuning:\n",
    "            node_origin[node] = 'both'\n",
    "        elif node in nodes_browsing:\n",
    "            node_origin[node] = 'browsing'\n",
    "        else:\n",
    "            node_origin[node] = 'tuning'\n",
    "\n",
    "    # Create combined graph\n",
    "    G_combined = nx.Graph()\n",
    "    for node, origin in node_origin.items():\n",
    "        G_combined.add_node(node, origin=origin)\n",
    "\n",
    "    # Add edges from both graphs\n",
    "    G_combined.add_edges_from(G_browsing.edges)\n",
    "    G_combined.add_edges_from(G_tuning.edges)\n",
    "    \n",
    "    return G_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4260ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Get node colors based on 'origin' attribute\n",
    "# color_map = {\n",
    "#     'browsing': 'skyblue',\n",
    "#     'tuning': 'salmon',\n",
    "#     'both': 'yellowgreen'\n",
    "# }\n",
    "# node_colors = [color_map[G_combined.nodes[n]['origin']] for n in G_combined.nodes]\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# nx.draw_networkx(\n",
    "#     G_combined,\n",
    "#     with_labels=False,\n",
    "#     node_color=node_colors,\n",
    "#     edge_color='gray',\n",
    "#     node_size=40,\n",
    "#     alpha=0.8\n",
    "# )\n",
    "# plt.title(\"Combined Hashtag Co-occurrence Network (Node Color by Origin)\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b18d99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_combined = build_overall_network(df_tuning, df_browsing, hashtag_col='hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a145dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def export_graph_to_csv(G, nodes_path='nodes.csv', edges_path='edges.csv'):\n",
    "    \"\"\"\n",
    "    Export nodes (with attributes) and edges of a NetworkX graph to CSV files.\n",
    "    \"\"\"\n",
    "    # Export nodes\n",
    "    with open(nodes_path, 'w', newline='', encoding='utf-8') as f_nodes:\n",
    "        writer = csv.writer(f_nodes)\n",
    "        writer.writerow(['id', 'node', 'origin'])\n",
    "        for node, data in G.nodes(data=True):\n",
    "            writer.writerow([node, node, data.get('origin', '')])\n",
    "\n",
    "    # Export edges\n",
    "    with open(edges_path, 'w', newline='', encoding='utf-8') as f_edges:\n",
    "        writer = csv.writer(f_edges)\n",
    "        writer.writerow(['source', 'target'])\n",
    "        for u, v in G.edges():\n",
    "            writer.writerow([u, v])\n",
    "\n",
    "# Example usage:\n",
    "# export_graph_to_csv(G_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb60379",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graph_to_csv(G_combined, nodes_path='../output/diabetes/nodes.csv', edges_path='../output/diabetes/edges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208802a",
   "metadata": {},
   "source": [
    "# Venn Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa231ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequencies_overall(df_browsing, df_tuning, word_col='hashtags'):\n",
    "    \"\"\"Return a DataFrame of word frequencies from a column of word lists.\"\"\"\n",
    "    all_words_browsing = [word for words_list in df_browsing[word_col] for word in words_list]\n",
    "    all_words_tuning = [word for words_list in df_tuning[word_col] for word in words_list]\n",
    "\n",
    "    all_words = all_words_browsing + all_words_tuning\n",
    "\n",
    "    word_freqs = Counter(all_words)\n",
    "    word_freqs_df = pd.DataFrame.from_dict(word_freqs, orient='index', columns=['count']).reset_index().rename({'index':'word'}, axis=1)\n",
    "    word_freqs_df = word_freqs_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "    # add information about source: only browsing, only tuning, or both\n",
    "    word_freqs_df['source'] = word_freqs_df['word'].apply(lambda word: \n",
    "        'both' if (word in all_words_browsing and word in all_words_tuning) \n",
    "        else 'browsing' if word in all_words_browsing \n",
    "        else 'tuning' if word in all_words_tuning\n",
    "        else 'unknown'\n",
    "    )\n",
    "\n",
    "    return word_freqs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f2e3359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>#fyp</td>\n",
       "      <td>475</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>#type2diabetes</td>\n",
       "      <td>134</td>\n",
       "      <td>tuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#foryou</td>\n",
       "      <td>117</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>#diabetes</td>\n",
       "      <td>114</td>\n",
       "      <td>tuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>#viral</td>\n",
       "      <td>112</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#fypã‚·</td>\n",
       "      <td>99</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>#prediabetes</td>\n",
       "      <td>93</td>\n",
       "      <td>tuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>#foryoupage</td>\n",
       "      <td>93</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>#bloodsugar</td>\n",
       "      <td>91</td>\n",
       "      <td>tuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>#insulinresistance</td>\n",
       "      <td>82</td>\n",
       "      <td>tuning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  count  source\n",
       "28                  #fyp    475    both\n",
       "2961      #type2diabetes    134  tuning\n",
       "8                #foryou    117    both\n",
       "2840           #diabetes    114  tuning\n",
       "34                #viral    112    both\n",
       "4                  #fypã‚·     99    both\n",
       "2963        #prediabetes     93  tuning\n",
       "46           #foryoupage     93    both\n",
       "2970         #bloodsugar     91  tuning\n",
       "2965  #insulinresistance     82  tuning"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_freq = get_word_frequencies_overall(df_browsing, df_tuning, word_col='hashtags')\n",
    "all_word_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6a20a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_freq.to_csv('../output/diabetes/word_frequencies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482593ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "css_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
